# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.
# SPDX-License-Identifier: Apache-2.0

from functools import lru_cache

from sqlalchemy import BIGINT, Integer, bindparam, select, sql
from sqlalchemy.dialects.postgresql import pg_catalog
from sqlalchemy.dialects.postgresql.base import PGDDLCompiler, PGDialect, PGTypeCompiler
from sqlalchemy.schema import ForeignKeyConstraint, PrimaryKeyConstraint
from sqlalchemy.sql import expression


class AuroraDSQLDDLCompiler(PGDDLCompiler):
    dialect: "AuroraDSQLDialect"
    DEFAULT_SEQUENCE_CACHE_SIZE = 65536

    def visit_create_sequence(self, create, **kw):
        """
        Override to add CACHE parameter required by DSQL
        and convert INTEGER to BIGINT.
        DSQL doesn't support INTEGER sequences.
        """

        sequence = create.element
        if sequence.data_type is not None:
            if isinstance(sequence.data_type, Integer):
                sequence.data_type = BIGINT()

        text = super().visit_create_sequence(create, **kw)
        # Add CACHE if not already present
        if "CACHE" not in text.upper():
            text += f" CACHE {self.DEFAULT_SEQUENCE_CACHE_SIZE}"
        return text

    def get_column_specification(self, column, **kw):
        """Override to use IDENTITY instead of SERIAL for autoincrement columns"""
        # Check if column has an explicit sequence
        has_sequence = (
            column.default is not None
            and hasattr(column.default, "is_sequence")
            and column.default.is_sequence
        )

        if has_sequence:
            # Build column spec with sequence default
            colspec = self.preparer.format_column(column)
            colspec += " " + self.type_compiler.process(
                column.type, type_expression=column
            )

            if not column.nullable:
                colspec += " NOT NULL"

            # Add DEFAULT nextval('sequence_name')
            sequence = column.default
            colspec += f" DEFAULT nextval('{self.preparer.format_sequence(sequence)}')"

            return colspec

        # Check if this is an identity column (autoincrement without explicit sequence)
        is_identity = column.autoincrement and column.primary_key

        if is_identity:
            # Build column spec manually to avoid SERIAL
            colspec = self.preparer.format_column(column)
            colspec += " BIGINT"  # DSQL requires BIGINT for identity

            if not column.nullable:
                colspec += " NOT NULL"

            # Use cache from Identity if provided, otherwise use default
            cache = self.DEFAULT_SEQUENCE_CACHE_SIZE
            if (
                hasattr(column, "identity")
                and column.identity
                and column.identity.cache is not None
            ):
                cache = column.identity.cache

            colspec += f" GENERATED BY DEFAULT AS IDENTITY (CACHE {cache})"

            return colspec
        else:
            return super().get_column_specification(column, **kw)

    def create_table_constraints(
        self, table, _include_foreign_key_constraints=None, **kw
    ):
        """
        modified from https://github.com/sqlalchemy/sqlalchemy/blob/rel_2_0_41/lib/sqlalchemy/sql/compiler.py
        """

        constraints = []
        if table.primary_key:
            constraints.append(table.primary_key)

        all_fkcs = table.foreign_key_constraints
        if _include_foreign_key_constraints is not None:
            omit_fkcs = all_fkcs.difference(_include_foreign_key_constraints)
        else:
            omit_fkcs = set()

        constraints.extend(
            [
                c
                for c in table._sorted_constraints
                if c is not table.primary_key and c not in omit_fkcs
            ]
        )

        constraints_without_fk = []
        for constraint in table.constraints:
            # Disable foreign key creation since DSQL
            # doesn't support foreign key
            if isinstance(constraint, ForeignKeyConstraint):
                pass
            # Skip empty primary key constraints
            elif (
                isinstance(constraint, PrimaryKeyConstraint) and not constraint.columns
            ):
                pass
            else:
                constraints_without_fk.append(constraint)

        constraints = constraints_without_fk

        return ", \n\t".join(
            p
            for p in (
                self.process(constraint)
                for constraint in constraints
                if (constraint._should_create_for_compiler(self))
                and (
                    not self.dialect.supports_alter
                    or not getattr(constraint, "use_alter", False)
                )
            )
            if p is not None
        )

    def visit_create_index(self, create, **kw):
        """
        modified from https://github.com/sqlalchemy/sqlalchemy/blob/rel_2_0_41/lib/sqlalchemy/dialects/postgresql/base.py
        """
        preparer = self.preparer
        index = create.element
        self._verify_index_table(index)
        text = "CREATE "
        if index.unique:
            text += "UNIQUE "

        text += "INDEX "

        if self.dialect._supports_create_index_async:
            text += "ASYNC "

        if create.if_not_exists:
            text += "IF NOT EXISTS "

        index_name = self._prepared_index_name(index, include_schema=False)
        table_name = preparer.format_table(index.table)
        text += f"{index_name} ON {table_name} "

        text += "({})".format(
            ", ".join(
                [
                    self.sql_compiler.process(
                        (
                            expr.self_group()
                            if not isinstance(expr, expression.ColumnClause)
                            else expr
                        ),
                        include_table=False,
                        literal_binds=True,
                    )
                    for expr in index.expressions
                ]
            )
        )

        includeclause = index.dialect_options[self.dialect.name]["include"]
        if includeclause:
            inclusions = [
                index.table.c[col] if isinstance(col, str) else col
                for col in includeclause
            ]
            text += " INCLUDE ({})".format(
                ", ".join([preparer.quote(c.name) for c in inclusions])
            )

        nulls_not_distinct = index.dialect_options[self.dialect.name][
            "nulls_not_distinct"
        ]
        if nulls_not_distinct is True:
            text += " NULLS NOT DISTINCT"
        elif nulls_not_distinct is False:
            text += " NULLS DISTINCT"

        return text


class AuroraDSQLDialect(PGDialect):
    name = "auroradsql"
    default_schema_name = "public"

    ddl_compiler = AuroraDSQLDDLCompiler
    type_compiler = PGTypeCompiler

    supports_sequences = True
    preexecute_autoincrement_sequences = True
    supports_identity_columns = True
    insert_returning = True
    supports_ddl_transactions = False

    supports_alter = False
    supports_native_enum = False

    _supports_create_index_async = True

    def do_execute(self, cursor, statement, parameters, context=None):
        """
        Execute statement and commit immediately if DDL
        since DSQL doesn't support multiple DDL in one transaction
        """
        cursor.execute(statement, parameters)
        # Commit after each DDL statement
        if context and context.isddl:
            cursor.connection.commit()

    def do_execute_no_params(self, cursor, statement, context=None):
        """
        Execute statement and commit immediately if DDL
        since DSQL doesn't support multiple DDL in one transaction
        """
        cursor.execute(statement)
        # Commit after each DDL statement
        if context and context.isddl:
            cursor.connection.commit()

    @lru_cache
    def _columns_query(self, schema, has_filter_names, scope, kind):
        """
        modified from https://github.com/sqlalchemy/sqlalchemy/blob/rel_2_0_41/lib/sqlalchemy/dialects/postgresql/base.py
        """

        # NOTE: the query with the default and identity options scalarx
        # subquery is faster than trying to use outer joins for them
        generated = (
            pg_catalog.pg_attribute.c.attgenerated.label("generated")
            if self.server_version_info is not None
            and self.server_version_info >= (12,)
            else sql.null().label("generated")
        )

        # the original code uses sql.func.json_build_object when server_version is
        # greater than version 10
        # json_build_object is not supported by Aurora DSQL
        # TODO: if json_build_object is supported in the future,
        # restore _columns_query function from original

        identity = sql.null().label("identity_options")

        # join lateral performs the same as scalar_subquery here
        default = (
            select(
                pg_catalog.pg_get_expr(
                    pg_catalog.pg_attrdef.c.adbin,
                    pg_catalog.pg_attrdef.c.adrelid,
                )
            )
            .select_from(pg_catalog.pg_attrdef)
            .where(
                pg_catalog.pg_attrdef.c.adrelid == pg_catalog.pg_attribute.c.attrelid,
                pg_catalog.pg_attrdef.c.adnum == pg_catalog.pg_attribute.c.attnum,
                pg_catalog.pg_attribute.c.atthasdef,
            )
            .correlate(pg_catalog.pg_attribute)
            .scalar_subquery()
            .label("default")
        )
        relkinds = self._kind_to_relkinds(kind)
        query = (
            select(
                pg_catalog.pg_attribute.c.attname.label("name"),
                pg_catalog.format_type(
                    pg_catalog.pg_attribute.c.atttypid,
                    pg_catalog.pg_attribute.c.atttypmod,
                ).label("format_type"),
                default,
                pg_catalog.pg_attribute.c.attnotnull.label("not_null"),
                pg_catalog.pg_class.c.relname.label("table_name"),
                pg_catalog.pg_description.c.description.label("comment"),
                generated,
                identity,
            )
            .select_from(pg_catalog.pg_class)
            # NOTE: postgresql support table with no user column, meaning
            # there is no row with pg_attribute.attnum > 0. use a left outer
            # join to avoid filtering these tables.
            .outerjoin(
                pg_catalog.pg_attribute,
                sql.and_(
                    pg_catalog.pg_class.c.oid == pg_catalog.pg_attribute.c.attrelid,
                    pg_catalog.pg_attribute.c.attnum > 0,
                    ~pg_catalog.pg_attribute.c.attisdropped,
                ),
            )
            .outerjoin(
                pg_catalog.pg_description,
                sql.and_(
                    pg_catalog.pg_description.c.objoid
                    == pg_catalog.pg_attribute.c.attrelid,
                    pg_catalog.pg_description.c.objsubid
                    == pg_catalog.pg_attribute.c.attnum,
                ),
            )
            .where(self._pg_class_relkind_condition(relkinds))
            .order_by(pg_catalog.pg_class.c.relname, pg_catalog.pg_attribute.c.attnum)
        )
        query = self._pg_class_filter_scope_schema(query, schema, scope=scope)
        if has_filter_names:
            query = query.where(
                pg_catalog.pg_class.c.relname.in_(bindparam("filter_names"))
            )
        return query
